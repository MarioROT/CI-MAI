---
title: "Master in Artificial Intelligence (CI-MAI) Evolutionary Computation Laboratory Part 2: **Evolution Strategies**"
author: "Lluís A. Belanche"
date: "`r format(Sys.time(), '%d %b %Y')`"
output: 
  rmarkdown::html_document:
    toc: true
    number_sections: false
    css: "vignette.css"
vignette: >
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(fig.align = "center", 
               out.width = "80%",
               fig.width = 6, fig.height = 5,
               dev = "svg", fig.ext = "svg",
               par = TRUE, # needed for setting hook 
               collapse = TRUE, # collapse input & output code in chunks
               warning = FALSE)

knit_hooks$set(par = function(before, options, envir)
  { if(before && options$fig.show != "none") 
       par(family = "sans", mar=c(4.1,4.1,1.1,1.1), mgp=c(3,1,0), tcl=-0.5)
})
```

```{r, message = FALSE}
library(cmaesr)
```

## Introduction

Evolution Strategies (ESs) are stochastic search algorithms inspired by the basic principles of biological evolution, genetics and natural selection. The special feature of the ES is the self-adaptation of mutation step sizes and the coevolution associated with it. Please refer to [Evolution strategies–a comprehensive introduction](https://link.springer.com/article/10.1023/A:1015059928466) or [Evolution strategies for continuous optimization: A survey of the state-of-the-art](https://www.sciencedirect.com/science/article/pii/S221065021930584X) for recent surveys, as well as the many references provided in the last slides of the corresponding lecture.


The **cmaesr** package implements the latest version in the breed, the popular _Covariance Matrix Adaptation - Evolution Strategy_ (CMA-ES) optimizer for non-linear, non-convex numerical optimization problems in pure R.

Please refer to:

- https://cran.r-project.org/web/packages/cmaesr/index.html
- https://github.com/jakobbossek/cmaesr

for a complete introduction to the software. Please address questions and missing features about the _cmaesr_ package to the author Jakob Bossek at j.bossek@gmail.com. 
```{r}

```

## Example 1

Assume we want to minimize the 2D Ackley Function. To accomplish this task we first need to define the objective function as a _smoof_ function (unless it is already a built-in function, which is the case). This function is then passed with some control arguments to the main function of the package, _cmaes_ (see below).

The _Ackley_ function is widely used for testing optimization algorithms. In its two-dimensional form ($d=2$), as shown in the plots, it is characterized by a nearly flat outer region, and a large hole at the centre. The function poses a high risk for optimization algorithms, particularly hillclimbing algorithms, to be trapped in one of its many local minima.

Recommended variable values are: $a = 20, b = 0.2$ and $c = 2\pi$. 

```{r}
library(ggplot2)
library(plot3D)

# first generate the objective smoof function (and plot it)
obj.fn = makeAckleyFunction(dimensions = 2L)
print(obj.fn)
print(autoplot(obj.fn))
plot3D(obj.fn, length.out = 50L, contour = TRUE)
```

Note that the function has a global optimum objective value of 0 at the origin (this information is available upon printing the R object). The function is usually evaluated on the hypercube $[-32.768, 32.768]$, although it may also be restricted to a smaller domain:

\[f(\mathbf{x}) = -a\;\exp\left(-b \sqrt{\frac{1}{D}\sum_{i=1}^D x_i^2}\right)
        - \exp\left(\frac{1}{D}\sum_{i=1}^D \cos(c\cdot x_i)\right) + a + \exp(1)\]

 <!--- ```{r echo=FALSE, out.width='80%'}
knitr::include_graphics('./ackley2.png')
``` --->

```{r}
res = cmaes(
    obj.fn, 
    monitor = makeSimpleMonitor(),
    control = list(
        sigma = 1.5, # initial step size
        lambda = 50, # number of offspring
        stop.ons = c(
            list(stopOnMaxIters(100)), # stop after 100 iterations
            getDefaultStoppingConditions() # or after default stopping conditions
        )
    )
)
print(res)
```


The results are (usually but not always) very good indeed. Try to experiment with the function dimension ($D$ in the formula and parameter _dimensions_ in the code call to _makeAckleyFunction_).

## Setting up a user-defined objective function by hand

For illustration purposes, let us consider the (toy) problem of finding the (global) minimum of the multimodal target function $f(x) = x sin(3x)$ on the closed interval $[0, 2\pi]$. We define our target function via the _makeSingleObjectiveFunction()_ method providing a name, the function itself and a parameter set. We can display the function within the box constraints with _ggplot_.

```{r}
obj.fn = makeSingleObjectiveFunction(
  name = "This is my first function name",
  fn = function(x) x * sin(3*x),
  par.set = makeNumericParamSet("x", len = 1L, lower = 0, upper = 2 * pi)
)

print(obj.fn)
print(getParamSet(obj.fn))
print(autoplot(obj.fn))
```

A perhaps nicer (and much more challenging) function is the so-called Doppler function:

\[f(\mathbf{x}) = \sqrt{x(1-x)} \sin \frac{2\pi(1+\epsilon)}{x+\epsilon}\]

where $\epsilon = 0.05$. As an exercise, plot this function, program it and optimise it with an ES.